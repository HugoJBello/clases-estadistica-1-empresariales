% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Variables estadísticas bidimensionales},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=3cm]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi



\title{Variables estadísticas bidimensionales}
\author{}
\date{}

\hypersetup{
colorlinks=true,
    urlcolor=PineGreen,
    citecolor=PineGreen,
}
\usepackage{fancyhdr}
\usepackage{caption}
\pagestyle{empty}
\pagestyle{fancy}

\fancyhead[LE,RO]{Variables estadísticas bidimensionales}
\fancyhead[LO,RE]{}
\fancyfoot[LE,RO]{\thepage}
\fancyfoot[C]{}

\renewcommand{\familydefault}{\sfdefault}

\begin{document}




\maketitle

En ocasiones los datos se presentan en pares \((x,y)\). Es decir que al
recoger los datos no solo tenemos una variable, sino dos y hay una
correspondencia entre los valores de una y los de la otra.

Pensemos en el siguente ejemplo:

\hypertarget{ejemplo}{%
\subsubsection{Ejemplo}\label{ejemplo}}

Una empresa observa que parece haber una relación fuerte entre las
ventas en enero y las ventas en febrero. Para ello se recogen los datos
de 9 años y se anotan en una tabla las ventas de enero y febrero de cada
año en miles de euros.

\begin{longtable}[]{@{}ll@{}}
\toprule
ventas enero & ventas febrero\tabularnewline
\midrule
\endhead
142.74 & 69.06\tabularnewline
146.58 & 70.62\tabularnewline
149.01 & 72.03\tabularnewline
151.72 & 73.48\tabularnewline
154.12 & 74.89\tabularnewline
158.23 & 76.48\tabularnewline
160.19 & 77.85\tabularnewline
165.46 & 79.54\tabularnewline
168.82 & 81.05\tabularnewline
\bottomrule
\end{longtable}

Para analizar estos datos, podríamos trabajar con cada variable por
separado (calculando medias, varianzas, haciendo gráficas\ldots{}), pero
se perdería la relación entre ambas. Siguendo este procedimiento sería
dificil observar por ejemplo como a mayores ventas en enero corresponden
mayores ventas en febrero.

Para ello trabajamos con las dos variables juntas, a través de la
\textbf{Covarianza} y el \textbf{coeficiente de correlación de pearson}.
Mediante ellos intentaremos capturar la relación de dependencia entre
ambas variables, particularmente la \emph{dependencia lineal,}, que
ocurre cuando una de las variables puede ser aproximadas a partir de la
otra mediante una recta.

\hypertarget{covarianza}{%
\section{Covarianza}\label{covarianza}}

La \textbf{covarianza} es un valor que indica el grado de variación
conjunta de dos variables aleatorias respecto a sus medias. Es el dato
básico para determinar si existe una dependencia entre ambas variables y
además es el dato necesario para estimar otros parámetros básicos, como
el coeficiente de correlación lineal.

Supongamos que tenemos unos datos
\[(x_1, y_1), (x_2, y_2), (x_3,y_3), \ldots (x_N,y_N)\]

La covarianza se denota por \(S_{xy}\) y se define como

\[ S_{xy} = \frac{1}{N}\sum^N_{i=1}(x_i - \overline{x})(y_i - \overline{y}) \]
\[ =\frac{1}{N}((x_1- \overline x)(y_1 - \overline y)+ (x_2- \overline x)(y_2 - \overline y)+ \ldots +(x_N- \overline x)(y_N - \overline y))\]

donde \(\overline x\) denota la media de la primera variable (\(x\)), e
\(\overline y\) denota la media de la segunda (\(y\))

\hypertarget{ejemplo-1}{%
\subsection{Ejemplo}\label{ejemplo-1}}

Para entender cómo calcularlo, usaremos el ejemplo anterior. Primero
calculamos la media de ambas variables. En este caso como todos los
datos son distintos no hay frecuencias así que para calcular las medias
basta sumar y dividir entre el número de datos.

Obtenemos \(\overline x \cong155.207\), \(\overline y \cong77.337\).
Añadimos una columna calculando las multiplicaciones
\((x_i - \overline{x})(y_i - \overline{y})\)

\begin{longtable}[]{@{}lll@{}}
\toprule
\(x_i\) & \(y_i\) &
\((x_i - \overline{x})(y_i - \overline{y})\)\tabularnewline
\midrule
\endhead
142.74 & 69.06 & 80.389\tabularnewline
146.58 & 70.62 & 21.981\tabularnewline
149.01 & 72.03 & 16.658\tabularnewline
151.72 & 73.48 & 4.142\tabularnewline
154.12 & 74.89 & -1.916\tabularnewline
158.23 & 76.48 & -1.564\tabularnewline
160.19 & 77.85 & 2.502\tabularnewline
165.46 & 79.54 & 27.908\tabularnewline
168.82 & 81.05 & 114.372\tabularnewline
\bottomrule
\end{longtable}

y para calcular la covarianza basta sumar esta tercera columna y dividir
entre el número de datos

\[S_{xy} \cong 264.474/9 \cong 29.386\]

\hypertarget{el-gruxe1fico-nubes-de-puntos}{%
\subsection{El gráfico nubes de
puntos}\label{el-gruxe1fico-nubes-de-puntos}}

Una manera de visualizar la relación o dependencia entre las dos
variables es dibujar cada punto \((x_i, y_i)\) en el plano.

En el ejemplo anterior, el gráfico sería el siguente.

\begin{figure}
\centering
\includegraphics[width=3.64583in,height=\textheight]{cloud.png}
\caption{nube de puntos}
\end{figure}

\hypertarget{coeficiente-de-correlaciuxf3n-de-pearson}{%
\section{Coeficiente de correlación de
Pearson}\label{coeficiente-de-correlaciuxf3n-de-pearson}}

El coeficiente de \textbf{correlación de Pearson} es una medida de
dependencia lineal entre dos variables estadísticas cuantitativas. A
diferencia de la covarianza, la correlación de Pearson es independiente
de la escala de medida de las variables.

Se define como

\[\rho_{XY} = \frac{S_{xy}}{S_X S_Y}\]

donde \(S_{xy}\) de nota la covarianza, \(S_X\) denota la desviación
típica de la primera variable y \(S_Y\) la desviación típica de la
segunda.

en el ejemplo anterior, si calculamos además la desviación típica de
\(X\) e \(Y\) obtenemos

\[S_x \cong 8.205\] \[S_y \cong 3.920\]

luego

\[\rho_{XY}\cong\frac{29.386}{8.205 \cdot 3.920} \cong 0.913\]

Deducimos de aquí que dado que el coeficiente de correlación de Pearson
es cercano a 1 existe una dependencia lineal directa entre las ventas de
enero y febrero

\hypertarget{interpretaciuxf3n-del-coeficiente-de-correlaciuxf3n-de-pearson}{%
\subsection{Interpretación del coeficiente de correlación de
Pearson}\label{interpretaciuxf3n-del-coeficiente-de-correlaciuxf3n-de-pearson}}

\begin{itemize}
\item
  Si \(\rho_{XY}>{0}\) hay dependencia lineal directa (positiva), es
  decir, a grandes valores de \(X\) corresponden grandes valores de
  \(Y\).

  \begin{figure}
  \centering
  \includegraphics[width=2.60417in,height=\textheight]{cloud.png}
  \caption{nube de puntos correlación positiva}
  \end{figure}
\item
  Si \(\rho_{XY} ={0}\) se interpreta como la no existencia de una
  relación lineal entre las dos variables.

  \begin{figure}
  \centering
  \includegraphics[width=2.60417in,height=\textheight]{cloud_cero.png}
  \caption{nube de puntos correlación 0}
  \end{figure}
\item
  Si \(\rho_{XY}<{0}\) hay dependencia lineal inversa o negativa, es
  decir, a grandes valores de \(X\) corresponden pequeños valores de
  \(Y\).

  \begin{figure}
  \centering
  \includegraphics[width=2.60417in,height=\textheight]{cloud_menos.png}
  \caption{nube de puntos correlación negativa}
  \end{figure}
\end{itemize}

\hypertarget{regresiuxf3n-simple}{%
\section{Regresión simple}\label{regresiuxf3n-simple}}

En las nubes de puntos que hemos utilizado hasta ahora, veíamos como en
los casos en que \(\rho_{XY}\) es cercano a \(-1\) o \(1\), los puntos
\((X,Y)\) parecen acercarse a una recta que puede ajustarse visualmente.
Esta recta es la \textbf{recta de regresión}.

En esta sección, aprenderemos a calcular la línea de regresión de manera
más precisa, usando la ecuación más sencilla que relaciona las dos
variables matemáticamente. Aquí, examinaremos sólo relaciones lineales
entre dos variables. Recordemos que la ecuación de una recta viene dada
por

\[Y= a + b X \]

Habitualmente, dados unas variables \(X\) e \(Y\), será la variable
\(Y\) la que querremos predecir a partir de la \(X\), por eso llamaremos
a \(Y\) \emph{variable dependiente} ya a la \(X\) \emph{variable
independiente}.

\hypertarget{muxe9todo-de-muxednimos-cuadrados}{%
\subsection{Método de mínimos
cuadrados}\label{muxe9todo-de-muxednimos-cuadrados}}

Imaginemos que tenemos una recta

\[f(X)= a + b X\]

El valor \(f(X)\) representa el valor con el que intentamos predecir
\(Y\). Por lo tanto el error (o residuo) de la predicción es
precisamente \[Y - f(X) = Y- a - b X\]

Una manera de trabajar con el error es trabajar con el cuadrado de la
expresión anterior, es decir, el cuadrado del error de la predicción

\[(Y- f(X))^2 = (Y- a - bX)^2\]

Si tenemos una muestra

\[(x_1, y_1), (x_2, y_2), (x_3,y_3), \ldots (x_N,y_N)\]

Y un modelo como el anterior \(f(X) = a + bY\), los errores medidos de
la forma anterior son las distancias en vertical entre la recta y cada
punto como puede verse en la figura siguiente:

\begin{figure}
\centering
\includegraphics[width=4.6875in,height=\textheight]{least_squares.png}
\caption{los cuadrados de las distancias son precisamente los errores
\((Y- f(X))^2\)}
\end{figure}

De tal modo que podemos decir que el error \textbf{global} de aproximar
\(Y\) con la recta \(f(X)= a+bX\) se puede medir como la suma de todos
los cuadrados de las distancias anteriores. Pensemos que cuanto más
alejados estén los puntos de la recta, \emph{peor} aproxima la recta.

Por lo tanto definimos el \textbf{residuo suma de cuadrados} como

\[S(a,b) =  \sum^n_{i=1} (y_i - f(x_i))^2 =  \sum^n_{i=1} (y_i - a -b\cdot x_i)^2\]

Lo llamamos de esta manera \(S(a,b)\) puesto que es el error que se
produce al elegir \(a\) y \(b\) como parámetros de la recta de
regresión.

De este modo, los valores de \(a\) y \(b\) que \textbf{menor error de
aproximación} \(S(a,b)\) produzcan serán los más deseados. Esos valores
precisamente son los que definen la \textbf{recta de regresión}.

Para encontrar esos valores debemos calcular el mínimo de la función
\(S(a,b)\)

deberemos calcular

\[\frac {\partial S}{\partial a}=0\]
\[\frac {\partial S}{\partial b}=0\]

resolver el sistema y averiguar que sea mínimo. Si hacemos esto
encontraremos que

\[a = \overline{y} - \frac{S_{XY}}{S^2_X} \overline x\]
\[b = \frac{S_{XY}}{S^2_X}\]

\hypertarget{coeficiente-de-determinaciuxf3n-r2}{%
\subsection{\texorpdfstring{Coeficiente de determinación
\(R^2\)}{Coeficiente de determinación R\^{}2}}\label{coeficiente-de-determinaciuxf3n-r2}}

El coeficiente de determinación se define como el cuadrado del
coeficiente de correlación de pearson:

\[R^2 = \rho ^2\]

Este valor da una idea de \textbf{cómo de bien} podemos aproximar a los
valores de \(Y\) usando la recta de regresión

El coeficiente de determinación está comprendido entre 0 y 1. Cuanto más
se aproxime a 0, peor es el modelo de regresión lineal para describir la
relación entre las variables. Cuanto más se aproxime a 1, mejor es el
modelo.

No existe un criterio inequívoco sobre el mínimo valor exigible para que
el modelo de regresión lineal sea aceptable. En general, se considera
inadmisible un modelo con \(R<0.5\)

\hypertarget{metodo-completo-del-cuxe1lculo-de-la-recta-de-regresiuxf3n}{%
\subsection{Metodo completo del cálculo de la recta de
regresión}\label{metodo-completo-del-cuxe1lculo-de-la-recta-de-regresiuxf3n}}

Si tenemos unos datos

\[(x_1, y_1), (x_2, y_2), (x_3,y_3), \ldots (x_N,y_N)\]

Para calcular la \textbf{recta de regresión de \(Y\) sobre \(X\)} (y por
lo tanto predecir \(Y\) usando \(X\) debemos):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  calcular \(\overline x\), \(\overline y\), \(S_{XY}\), \(S_X\) y
  \(S_Y\). Esto nos permitirá calcular el coeficiente de correlación de
  Pearson \(\rho\) \[\rho = \frac{S_{XY}}{S_X S_Y}\]
\item
  Interpretar \(\rho\): Un valor cercano a 1 es dependencia lineal
  directa. Un valor cercano a \(-1\) indirecta, y un valor cercano a 0
  implica no dependencia lineal.
\item
  Calcular los coeficientes \(a\) y \(b\) de la recta usando

  \[a = \overline{y} - \frac{S_{XY}}{S^2_X} \overline x\]
  \[b = \frac{S_{XY}}{S^2_X}\]
\item
  Calcular el coeficiente de determinación \[R^2 = \rho^2\] e
  interpretarlo. Un valor cercano a 0 significa que el modelo no
  aproxima bien, mientras que un valor cercano a 1 significa que el
  modelo es capaz de aproximar bien los valores de \(Y\) a partir de x
\end{enumerate}

Si ahora tenemos un nuevo valor de \(x\) y queremos estimar un valor de
\(Y\) basta hacer

\[y = a + b x\]

con los valores obtenidos en el método anterior.

\hypertarget{ejercicios}{%
\section{Ejercicios}\label{ejercicios}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Los siguientes datos corresponden al precio de un porducto y a la
  cantidad ofertada:

  \begin{longtable}[]{@{}ll@{}}
  \toprule
  cantidad ofertada (miles) & precio (euros)\tabularnewline
  \midrule
  \endhead
  1 & 3.5\tabularnewline
  5 & 5\tabularnewline
  10 & 8\tabularnewline
  15 & 8.5\tabularnewline
  20 & 12.5\tabularnewline
  25 & 13\tabularnewline
  30 & 15\tabularnewline
  \bottomrule
  \end{longtable}

  Calcula la covarianza y el coeficiente de correlación de Pearson e
  interprétalo. ¿Se cumple la ley de la oferta?
\end{enumerate}

\end{document}